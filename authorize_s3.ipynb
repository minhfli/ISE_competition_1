{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ad9d890",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T17:10:51.464070Z",
     "iopub.status.busy": "2024-03-13T17:10:51.463393Z",
     "iopub.status.idle": "2024-03-13T17:10:52.833615Z",
     "shell.execute_reply": "2024-03-13T17:10:52.831992Z"
    },
    "papermill": {
     "duration": 1.383522,
     "end_time": "2024-03-13T17:10:52.837156",
     "exception": false,
     "start_time": "2024-03-13T17:10:51.453634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/glove6b/glove.6B.200d.txt\n",
      "/kaggle/input/glove6b/glove.6B.50d.txt\n",
      "/kaggle/input/glove6b/glove.6B.300d.txt\n",
      "/kaggle/input/glove6b/glove.6B.100d.txt\n",
      "/kaggle/input/ise-competition-1/sample_submission/sample_submission.csv\n",
      "/kaggle/input/ise-competition-1/test/test.csv\n",
      "/kaggle/input/ise-competition-1/train/train.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file, 'r') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "    return words_to_index, index_to_words, word_to_vec_map\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "\n",
    "def one_hot(array):\n",
    "    unique, inverse = np.unique(array, return_inverse=True)\n",
    "    onehot = np.eye(unique.shape[0])[inverse]\n",
    "    return unique,onehot\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab30621c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T17:10:52.855415Z",
     "iopub.status.busy": "2024-03-13T17:10:52.853890Z",
     "iopub.status.idle": "2024-03-13T17:10:55.728638Z",
     "shell.execute_reply": "2024-03-13T17:10:55.726695Z"
    },
    "papermill": {
     "duration": 2.886841,
     "end_time": "2024-03-13T17:10:55.731739",
     "exception": false,
     "start_time": "2024-03-13T17:10:52.844898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "train_csv=pd.read_csv(\"/kaggle/input/ise-competition-1/train/train.csv\")\n",
    "train=train_csv.to_numpy(dtype=str)\n",
    "id = train[:,0]\n",
    "seq = train[:,1]\n",
    "out = train[:,2]\n",
    "longest = max(seq, key=lambda x: len(re.findall(r'\\w+|\\S+', x.lower())))\n",
    "maxLen = len(re.findall(r'\\w+|\\S+', longest.lower()))\n",
    "maxLen = min(maxLen,200)\n",
    "print(maxLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1eb638e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T17:10:55.749187Z",
     "iopub.status.busy": "2024-03-13T17:10:55.747762Z",
     "iopub.status.idle": "2024-03-13T17:11:28.027239Z",
     "shell.execute_reply": "2024-03-13T17:11:28.025526Z"
    },
    "papermill": {
     "duration": 32.29204,
     "end_time": "2024-03-13T17:11:28.031245",
     "exception": false,
     "start_time": "2024-03-13T17:10:55.739205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('/kaggle/input/glove6b/glove.6B.200d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdf60d04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T17:11:28.048644Z",
     "iopub.status.busy": "2024-03-13T17:11:28.047758Z",
     "iopub.status.idle": "2024-03-13T17:11:28.058256Z",
     "shell.execute_reply": "2024-03-13T17:11:28.057028Z"
    },
    "papermill": {
     "duration": 0.022476,
     "end_time": "2024-03-13T17:11:28.061061",
     "exception": false,
     "start_time": "2024-03-13T17:11:28.038585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenize and create format\n",
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    \"\"\"\n",
    "    Converts an array of sentences (strings) into an array of indices corresponding to words in the sentences.\n",
    "    The output shape should be such that it can be given to `Embedding()` \n",
    "    \n",
    "    Arguments:\n",
    "    X -- array of sentences (strings), of shape (m,)\n",
    "    word_to_index -- a dictionary containing the each word mapped to its index\n",
    "    max_len -- maximum number of words in a sentence. You can assume every sentence in X is no longer than this. \n",
    "    \n",
    "    Returns:\n",
    "    X_indices -- array of indices corresponding to words in the sentences from X, of shape (m, max_len)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0]                                   # number of training examples\n",
    "    \n",
    "    # Initialize X_indices as a numpy matrix of zeros and the correct shape (≈ 1 line)\n",
    "    X_indices = np.zeros((m,max_len))\n",
    "    \n",
    "    for i in range(m):                               # loop over training examples\n",
    "        # Convert the ith training sentence to lower case and split it into words\n",
    "        sentence_words= re.findall(r'\\w+|\\S+', X[i].lower())\n",
    "        # Initialize j to 0\n",
    "        j = 0\n",
    "        # Loop over the words of sentence_words\n",
    "        for w in sentence_words:\n",
    "            # if w exists in the word_to_index dictionary\n",
    "            if w in word_to_index:\n",
    "                # Set the (i,j)th entry of X_indices to the index of the correct word.\n",
    "                X_indices[i, j] = word_to_index[w]\n",
    "                j = j+1    \n",
    "                if j>=max_len:\n",
    "                    break\n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2873f77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T17:11:28.078654Z",
     "iopub.status.busy": "2024-03-13T17:11:28.078217Z",
     "iopub.status.idle": "2024-03-13T17:11:31.583777Z",
     "shell.execute_reply": "2024-03-13T17:11:31.582786Z"
    },
    "papermill": {
     "duration": 3.517676,
     "end_time": "2024-03-13T17:11:31.586998",
     "exception": false,
     "start_time": "2024-03-13T17:11:28.069322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[358161. 292849.    452. 182574.    452.  47561. 239106. 262351. 239198.\n",
      "  268047.  60830. 357267. 124214. 268047. 254259. 130811.  42950.  60666.\n",
      "  185458. 243978. 231459. 193920. 101461.    452.  54719. 307030. 360916.\n",
      "  357267. 287480. 386426. 185458. 325900. 272931.    452. 388757.  72183.\n",
      "   64318. 268047. 357267. 143955.  42950. 336115. 281284. 372015. 323427.\n",
      "  357267. 382655.    867.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.]\n",
      " [193717. 259915. 269890. 267459. 360916. 239106. 357213. 357267. 155155.\n",
      "  243978.  71091.  43011. 241336. 246351.    867.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.]\n",
      " [188482. 179435. 219578. 172467. 383515.  43011. 163827. 336083.  82219.\n",
      "     452. 154324. 386475.    452.  60666. 175200. 128528. 357267. 178829.\n",
      "     452. 114254.  51583. 233321. 268047. 144909. 342883.    452. 175200.\n",
      "  361954. 336083. 188761. 388712.  54274.  49060. 268047. 357267. 166403.\n",
      "  289447. 323982. 319033.    867.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.]\n",
      " [182541. 226327. 192974. 340238.  60666. 384375. 225640. 154324. 388125.\n",
      "  356251. 269799. 357267. 333365. 147248. 110424. 340206.  73068.    452.\n",
      "  339061.  88127. 173082. 110049.  54719. 384410. 363143.    452.  51583.\n",
      "  225640.  60666. 188482. 151781. 393336.    452. 175450.  97856.  54719.\n",
      "  144250.    867.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.]\n",
      " [148434. 264613. 135870.    452. 264551. 141817. 163827.    452. 357267.\n",
      "  347945.  43797. 179435.  62700.  42950.  87776.  43011. 281738. 225630.\n",
      "  267399. 342245. 273429. 179435. 110236.  60666. 175200. 333162. 357981.\n",
      "   62066. 179435. 121892.    867.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "       0.      0.]]\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n",
      "['EAP' 'HPL' 'MWS']\n"
     ]
    }
   ],
   "source": [
    "X_train=sentences_to_indices(seq, word_to_index, maxLen)\n",
    "possible_output,Y_train=one_hot(out)\n",
    "print(X_train[0:5])\n",
    "print(Y_train[0:5])\n",
    "print(possible_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dae435f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T17:11:31.605474Z",
     "iopub.status.busy": "2024-03-13T17:11:31.604678Z",
     "iopub.status.idle": "2024-03-13T17:11:49.192222Z",
     "shell.execute_reply": "2024-03-13T17:11:49.190689Z"
    },
    "papermill": {
     "duration": 17.600505,
     "end_time": "2024-03-13T17:11:49.195387",
     "exception": false,
     "start_time": "2024-03-13T17:11:31.594882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 17:11:34.218957: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-13 17:11:34.219149: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-13 17:11:34.401470: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "np.random.seed(0)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7093c18f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T17:11:49.214688Z",
     "iopub.status.busy": "2024-03-13T17:11:49.213059Z",
     "iopub.status.idle": "2024-03-13T17:11:49.224985Z",
     "shell.execute_reply": "2024-03-13T17:11:49.223793Z"
    },
    "papermill": {
     "duration": 0.024333,
     "end_time": "2024-03-13T17:11:49.228225",
     "exception": false,
     "start_time": "2024-03-13T17:11:49.203892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    \"\"\"\n",
    "    Creates a Keras Embedding() layer and loads in pre-trained GloVe 50-dimensional vectors.\n",
    "    \n",
    "    Arguments:\n",
    "    word_to_vec_map -- dictionary mapping words to their GloVe vector representation.\n",
    "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
    "\n",
    "    Returns:\n",
    "    embedding_layer -- pretrained layer Keras instance\n",
    "    \"\"\"\n",
    "    \n",
    "    vocab_size = len(word_to_index) + 1              # adding 1 to fit Keras embedding (requirement)\n",
    "    any_word = next(iter(word_to_vec_map.keys()))\n",
    "    emb_dim = word_to_vec_map[any_word].shape[0]    # define dimensionality of your GloVe word vectors (= 50)\n",
    "      \n",
    "    # Initialize the embedding matrix as a numpy array of zeros.\n",
    "    emb_matrix = np.zeros((vocab_size,emb_dim))\n",
    "    \n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        emb_matrix[idx, :] = word_to_vec_map[word]\n",
    "\n",
    "    # Define Keras embedding layer with the correct input and output sizes\n",
    "    # Make it non-trainable.\n",
    "    embedding_layer = Embedding(vocab_size,emb_dim)\n",
    "\n",
    "    # Build the embedding layer, it is required before setting the weights of the embedding layer. \n",
    "    embedding_layer.build((None,)) # Do not modify the \"None\".  This line of code is complete as-is.\n",
    "    # Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    embedding_layer.trainable = False\n",
    "\n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a5ec88f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T17:11:49.245811Z",
     "iopub.status.busy": "2024-03-13T17:11:49.245072Z",
     "iopub.status.idle": "2024-03-13T17:11:49.254893Z",
     "shell.execute_reply": "2024-03-13T17:11:49.253291Z"
    },
    "papermill": {
     "duration": 0.022221,
     "end_time": "2024-03-13T17:11:49.258188",
     "exception": false,
     "start_time": "2024-03-13T17:11:49.235967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model Authorize_s3\n",
    "\n",
    "def Authorize_s3(input_shape,softmax_size, word_to_vec_map, word_to_index):\n",
    "    \"\"\"\n",
    "    Function creating the Emojify-v2 model's graph.\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the input, usually (max_len,)\n",
    "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
    "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
    "\n",
    "    Returns:\n",
    "    model -- a model instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define sentence_indices as the input of the graph.\n",
    "    # It should be of shape input_shape and dtype 'int32' (as it contains indices, which are integers).\n",
    "    sentence_indices = Input(shape=input_shape,dtype='int32')\n",
    "    # Create the embedding layer pretrained with GloVe Vectors (≈1 line)\n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec_map,word_to_index)\n",
    "    # Propagate sentence_indices through your embedding layer\n",
    "    embeddings = embedding_layer(sentence_indices)   \n",
    "    \n",
    "    # Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n",
    "    # The returned output should be a batch of sequences.\n",
    "    X = LSTM(units=256,return_sequences=True)(embeddings)\n",
    "    # Add dropout with a probability of 0.5\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
    "    # The returned output should be a single hidden state, not a batch of sequences.\n",
    "    X = LSTM(units=256,return_sequences=False)(X)\n",
    "    # Add dropout with a probability of 0.5\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Propagate X through a Dense layer \n",
    "    X = Dense(softmax_size)(X)\n",
    "    # Add a softmax activation\n",
    "    X = Activation('softmax')(X)\n",
    "    \n",
    "    # Create Model instance which converts sentence_indices into X.\n",
    "    model = Model(sentence_indices,X)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e875d09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T17:11:49.276003Z",
     "iopub.status.busy": "2024-03-13T17:11:49.275440Z",
     "iopub.status.idle": "2024-03-13T17:11:54.659006Z",
     "shell.execute_reply": "2024-03-13T17:11:54.657618Z"
    },
    "papermill": {
     "duration": 5.396332,
     "end_time": "2024-03-13T17:11:54.662015",
     "exception": false,
     "start_time": "2024-03-13T17:11:49.265683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">80,000,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">467,968</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">771</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m)       │    \u001b[38;5;34m80,000,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m467,968\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m525,312\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m771\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">80,994,451</span> (308.97 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m80,994,451\u001b[0m (308.97 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">994,051</span> (3.79 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m994,051\u001b[0m (3.79 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">80,000,400</span> (305.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m80,000,400\u001b[0m (305.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Authorize_s3((maxLen,),len(possible_output), word_to_vec_map, word_to_index)\n",
    "model.layers[0].trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c220b753",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T17:11:54.682840Z",
     "iopub.status.busy": "2024-03-13T17:11:54.682105Z",
     "iopub.status.idle": "2024-03-13T17:11:54.699042Z",
     "shell.execute_reply": "2024-03-13T17:11:54.697716Z"
    },
    "papermill": {
     "duration": 0.030959,
     "end_time": "2024-03-13T17:11:54.702293",
     "exception": false,
     "start_time": "2024-03-13T17:11:54.671334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b15d6c0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T17:11:54.721006Z",
     "iopub.status.busy": "2024-03-13T17:11:54.720537Z",
     "iopub.status.idle": "2024-03-13T21:58:24.676847Z",
     "shell.execute_reply": "2024-03-13T21:58:24.673134Z"
    },
    "papermill": {
     "duration": 17191.9495,
     "end_time": "2024-03-13T21:58:26.660119",
     "exception": false,
     "start_time": "2024-03-13T17:11:54.710619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m612/612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m569s\u001b[0m 922ms/step - accuracy: 0.4081 - loss: 1.0893\n",
      "Epoch 2/30\n",
      "\u001b[1m612/612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m528s\u001b[0m 863ms/step - accuracy: 0.4014 - loss: 1.0884\n",
      "Epoch 3/30\n",
      "\u001b[1m612/612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m602s\u001b[0m 928ms/step - accuracy: 0.3966 - loss: 1.0902\n",
      "Epoch 4/30\n",
      "\u001b[1m612/612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 918ms/step - accuracy: 0.4011 - loss: 1.0895\n",
      "Epoch 5/30\n",
      "\u001b[1m612/612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m619s\u001b[0m 914ms/step - accuracy: 0.3988 - loss: 1.0899\n",
      "Epoch 6/30\n",
      "\u001b[1m612/612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m539s\u001b[0m 877ms/step - accuracy: 0.4091 - loss: 1.0866\n",
      "Epoch 7/30\n",
      "\u001b[1m612/612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m581s\u001b[0m 908ms/step - accuracy: 0.4049 - loss: 1.0881\n",
      "Epoch 8/30\n",
      "\u001b[1m612/612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m547s\u001b[0m 884ms/step - accuracy: 0.4065 - loss: 1.0869\n",
      "Epoch 9/30\n",
      "\u001b[1m612/612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m588s\u001b[0m 927ms/step - accuracy: 0.4008 - loss: 1.0890\n",
      "Epoch 10/30\n",
      "\u001b[1m612/612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m568s\u001b[0m 927ms/step - accuracy: 0.3942 - loss: 1.0927\n",
      "Epoch 11/30\n",
      "\u001b[1m612/612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m621s\u001b[0m 926ms/step - accuracy: 0.4007 - loss: 1.0858\n",
      "Epoch 12/30\n",
      "\u001b[1m612/612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m634s\u001b[0m 945ms/step - accuracy: 0.4014 - loss: 1.0857\n",
      "Epoch 13/30\n",
      "\u001b[1m612/612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m577s\u001b[0m 872ms/step - accuracy: 0.4003 - loss: 1.0869\n",
      "Epoch 14/30\n",
      "\u001b[1m612/612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m535s\u001b[0m 875ms/step - accuracy: 0.4063 - loss: 1.0860\n",
      "Epoch 15/30\n",
      "\u001b[1m612/612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m588s\u001b[0m 917ms/step - accuracy: 0.4073 - loss: 1.0834\n",
      "Epoch 16/30\n",
      "\u001b[1m612/612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m536s\u001b[0m 874ms/step - accuracy: 0.3953 - loss: 1.0910\n",
      "Epoch 17/30\n",
      "\u001b[1m612/612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m557s\u001b[0m 910ms/step - accuracy: 0.4083 - loss: 1.0862\n",
      "Epoch 18/30\n",
      "\u001b[1m612/612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m539s\u001b[0m 880ms/step - accuracy: 0.4033 - loss: 1.0864\n",
      "Epoch 19/30\n",
      "\u001b[1m612/612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m586s\u001b[0m 920ms/step - accuracy: 0.4053 - loss: 1.0862\n",
      "Epoch 20/30\n",
      "\u001b[1m612/612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m591s\u001b[0m 870ms/step - accuracy: 0.4030 - loss: 1.0875\n",
      "Epoch 21/30\n",
      "\u001b[1m612/612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m547s\u001b[0m 894ms/step - accuracy: 0.3978 - loss: 1.0870\n",
      "Epoch 22/30\n",
      "\u001b[1m612/612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m564s\u001b[0m 897ms/step - accuracy: 0.3998 - loss: 1.0856\n",
      "Epoch 23/30\n",
      "\u001b[1m612/612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m575s\u001b[0m 919ms/step - accuracy: 0.3982 - loss: 1.0867\n",
      "Epoch 24/30\n",
      "\u001b[1m612/612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 912ms/step - accuracy: 0.4060 - loss: 1.0842\n",
      "Epoch 25/30\n",
      "\u001b[1m612/612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m560s\u001b[0m 915ms/step - accuracy: 0.3992 - loss: 1.0854\n",
      "Epoch 26/30\n",
      "\u001b[1m612/612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m556s\u001b[0m 909ms/step - accuracy: 0.4062 - loss: 1.0865\n",
      "Epoch 27/30\n",
      "\u001b[1m612/612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m551s\u001b[0m 900ms/step - accuracy: 0.4040 - loss: 1.0869\n",
      "Epoch 28/30\n",
      "\u001b[1m612/612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m568s\u001b[0m 910ms/step - accuracy: 0.4013 - loss: 1.0879\n",
      "Epoch 29/30\n",
      "\u001b[1m612/612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m553s\u001b[0m 895ms/step - accuracy: 0.4088 - loss: 1.0857\n",
      "Epoch 30/30\n",
      "\u001b[1m612/612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m541s\u001b[0m 861ms/step - accuracy: 0.4086 - loss: 1.0860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x785be641cd90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs = 30, batch_size = 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be0cd6f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T21:58:30.430424Z",
     "iopub.status.busy": "2024-03-13T21:58:30.428985Z",
     "iopub.status.idle": "2024-03-13T21:58:32.346306Z",
     "shell.execute_reply": "2024-03-13T21:58:32.344461Z"
    },
    "papermill": {
     "duration": 3.896789,
     "end_time": "2024-03-13T21:58:32.350603",
     "exception": false,
     "start_time": "2024-03-13T21:58:28.453814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('/kaggle/working/model_len200_embed200_ep30.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ca7052a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T21:58:36.073784Z",
     "iopub.status.busy": "2024-03-13T21:58:36.073197Z",
     "iopub.status.idle": "2024-03-13T21:58:37.015092Z",
     "shell.execute_reply": "2024-03-13T21:58:37.013731Z"
    },
    "papermill": {
     "duration": 2.889426,
     "end_time": "2024-03-13T21:58:37.017824",
     "exception": false,
     "start_time": "2024-03-13T21:58:34.128398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Still, as I urged our leaving Ireland with such inquietude and impatience, my father thought it best to yield.'\n",
      " 'If a fire wanted fanning, it could readily be fanned with a newspaper, and as the government grew weaker, I have no doubt that leather and iron acquired durability in proportion, for, in a very short time, there was not a pair of bellows in all Rotterdam that ever stood in need of a stitch or required the assistance of a hammer.'\n",
      " 'And when they had broken down the frail door they found only this: two cleanly picked human skeletons on the earthen floor, and a number of singular beetles crawling in the shadowy corners.'\n",
      " ...\n",
      " 'It is easily understood that what might improve a closely scrutinized detail, may at the same time injure a general or more distantly observed effect.'\n",
      " 'Be this as it may, I now began to feel the inspiration of a burning hope, and at length nurtured in my secret thoughts a stern and desperate resolution that I would submit no longer to be enslaved.'\n",
      " 'Long winded, statistical, and drearily genealogical as some of the matter was, there ran through it a continuous thread of brooding, tenacious horror and preternatural malevolence which impressed me even more than it had impressed the good doctor.']\n"
     ]
    }
   ],
   "source": [
    "test_csv=pd.read_csv(\"/kaggle/input/ise-competition-1/test/test.csv\")\n",
    "test=test_csv.to_numpy(dtype=str)\n",
    "id_test = test[:,0]\n",
    "seq_test = test[:,1]\n",
    "X_test=sentences_to_indices(seq_test, word_to_index, maxLen)\n",
    "print(seq_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22ad08ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T21:58:40.743551Z",
     "iopub.status.busy": "2024-03-13T21:58:40.743118Z",
     "iopub.status.idle": "2024-03-13T22:00:13.301771Z",
     "shell.execute_reply": "2024-03-13T22:00:13.300283Z"
    },
    "papermill": {
     "duration": 94.501411,
     "end_time": "2024-03-13T22:00:13.305028",
     "exception": false,
     "start_time": "2024-03-13T21:58:38.803617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 349ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_test= model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "162f602c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T22:00:16.978188Z",
     "iopub.status.busy": "2024-03-13T22:00:16.977398Z",
     "iopub.status.idle": "2024-03-13T22:00:17.269250Z",
     "shell.execute_reply": "2024-03-13T22:00:17.268042Z"
    },
    "papermill": {
     "duration": 2.148376,
     "end_time": "2024-03-13T22:00:17.271798",
     "exception": false,
     "start_time": "2024-03-13T22:00:15.123422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id       EAP       HPL       MWS\n",
      "0     id02310  0.414309  0.287499  0.298192\n",
      "1     id24541  0.414309  0.287499  0.298192\n",
      "2     id00134  0.394192  0.275336  0.330472\n",
      "3     id27757  0.394192  0.275336  0.330472\n",
      "4     id04081  0.394192  0.275336  0.330472\n",
      "...       ...       ...       ...       ...\n",
      "8387  id11749  0.394192  0.275336  0.330472\n",
      "8388  id10526  0.394193  0.275336  0.330472\n",
      "8389  id13477  0.414309  0.287499  0.298192\n",
      "8390  id13761  0.414309  0.287499  0.298192\n",
      "8391  id04282  0.414309  0.287499  0.298192\n",
      "\n",
      "[8392 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "#np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "#print(Y_test)\n",
    "eap_i=0\n",
    "hpl_i=0\n",
    "mws_i=0\n",
    "for i in range(len(possible_output)):\n",
    "    if possible_output[i]==\"EAP\":\n",
    "        eap_i=i\n",
    "    if possible_output[i]==\"HPL\":\n",
    "        hpl_i=i\n",
    "    if possible_output[i]==\"MWS\":\n",
    "        mws_i=i\n",
    "predict = []\n",
    "for i in range(len(id_test)):\n",
    "    predict.append(\n",
    "        {\n",
    "            'id' : id_test[i],\n",
    "            'EAP': Y_test[i][eap_i],\n",
    "            'HPL': Y_test[i][hpl_i],\n",
    "            'MWS': Y_test[i][mws_i],\n",
    "        }\n",
    "    )\n",
    "print(pd.DataFrame(predict))\n",
    "pd.DataFrame(predict).to_csv(\"/kaggle/working/predict.csv\",\n",
    "                            index=False,\n",
    "                            quotechar='\"',\n",
    "                            quoting=csv.QUOTE_NONNUMERIC)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7916195,
     "sourceId": 72272,
     "sourceType": "competition"
    },
    {
     "datasetId": 4589173,
     "sourceId": 7830641,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17374.733731,
   "end_time": "2024-03-13T22:00:22.102317",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-13T17:10:47.368586",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
